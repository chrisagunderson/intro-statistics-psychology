<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>lecture-07-introduction-to-statistical-significance.knit</title>
    <meta charset="utf-8" />
    <script src="lecture-07-introduction-to-statistical-significance_files/header-attrs/header-attrs.js"></script>
    <link href="lecture-07-introduction-to-statistical-significance_files/remark-css/hygge.css" rel="stylesheet" />
    <link href="lecture-07-introduction-to-statistical-significance_files/tile-view/tile-view.css" rel="stylesheet" />
    <script src="lecture-07-introduction-to-statistical-significance_files/tile-view/tile-view.js"></script>
    <link href="lecture-07-introduction-to-statistical-significance_files/animate.css/animate.xaringan.css" rel="stylesheet" />
    <link href="lecture-07-introduction-to-statistical-significance_files/tachyons/tachyons.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">










.center[
# PSYC 2300
## Introduction to Statistics
]

.center[
&lt;img src="img/intro-stats-title-logo.png" width="50%"/&gt;
]

.center[
### Lecture 07: Introduction to Statistical Significance

]

---

# Outline for today

.pull-left[

- Review parts of previous lectures

- Decisions in hypothesis testing

- Statistical power


]


.pull-right[
&lt;img src="https://images.unsplash.com/photo-1483546416237-76fd26bbcdd1?ixlib=rb-1.2.1&amp;ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;auto=format&amp;fit=crop&amp;w=1950&amp;q=80" /&gt;
]

---

# Hypothesis

.content-box-gray[

**Hypothesis**: a specific, clear, and testable proposition or predictive statement about the possible outcome of a scientific research study

]

--

When we use _samples_ to approximate _populations_, however, we always have **sampling error** (difference between the sample statistic and the population parameter)

--
.center[
.Large[
.pull-left[

Sample Statistic `\(\overline{x}\)`

]

.pull-right[

Population Parameter `\(\mu\)`

]

.center[
Sampling Error `\(\epsilon\)`

]
]
]


---

# Statistical Hypotheses

.content-box-gray[
**Null Hypothesis**: there is no change, no difference, or no relationship between variables
]



.pull-left[The difference observed is due only to .secondary[_sampling error_], and not to any real effects in the population]



.pull-right[
.content-box-blue[
.center[
**Null Hypothesis**
.Large[
`$$H_{0} = \epsilon$$`
]
]
]
]

---

# Statistical Hypotheses

.content-box-gray[
**Research Hypothesis**: there is change, a difference, or a relationship between variables
]



.pull-left[The difference observed is due to both sampling error and .secondary[a real effect]]



.pull-right[
.content-box-blue[
.center[
**Research Hypothesis**
.Large[
`$$H_{1} = \tau + \epsilon$$`
]
]
]
]

---

# Standard of Evidence

.content-box-gray[
**Alpha**: the probability value that is used to define which sample outcomes are considered very unlikely if `\(H_{0}\)` is true
]

--

The most common `\(\alpha = .05\)`

--

.content-box-gray[
**Critical Region**: The region (of the sampling distribution) that contains the sample outcomes that are considered _very unlikely_ if `\(H_{0}\)` is true
]


---

# Critical Region

.center[
&lt;img src="img/region-region.png" width="60%"/&gt;
]

---

# Compute a Test Statistic

.content-box-gray[
**Test statistic**: A numerical summary of the degree to which a sample is unlike the samples predicted by the null hypothesis, `\(H_{0}\)`
]

--

.content-box-blue[
.center[
**_z_-test statistic**

.Large[

`$$z_{\overline{x}} = \frac {\overline{x} - \mu_{\overline{x}}}{\sigma_{\overline{x}}}$$`

]
]
]

---

# Standard of Evidence

.center[
&lt;img src="img/z-test-rejection-region.png" width="57%"/&gt;
]

---

# _p_-value

.content-box-gray[
**_p_-value**: the probability of getting the observed or more extreme data, _assuming_ the null hypothesis is true
]

--

.pull-left[
.center[
If  `\(p &lt; \alpha\)`
]

- The data you observe is **not** likely due to just sampling error

- Reject the null hypothesis
]

--

.pull-right[

.center[
If `\(p &gt; \alpha\)`
]

- The data is likely due to sampling error

- We fail to to reject the null hypothesis
]

---

# _p_-value

.center[

&lt;img src="img/p-and-alpha-figure.png" width="80%"/&gt;
]

---

# Statistical Significance

.content-box-gray[

**Statistical Significance**: A result is said to be _significant_, or _statistically significant_, if it is very unlikely to occur when the null hypothesis is true. That is, the result is sufficient to reject the null hypothesis. Thus, a treatment has a significant effect if the decision from the hypothesis test is to reject `\(H_{0}\)`
]

.center[

&lt;img src="img/p-and-alpha-figure.png" width="50%"/&gt;


]

---


# Statistical Hypotheses


.pull-left[
.center[
**Null Hypothesis**  

`\(H_{0}\)`: No real effect exists  

.Large[
`$$\epsilon$$`
]

]
]

.pull-right[
.center[

**Research Hypothesis**   

`\(H_{1}\)`: A real effect does exist  

.Large[
`$$\tau + \epsilon$$`
]
]
]

--

.center[

### Because inferential statistics deals in _probabilities_, we always run the risk of making an error in our conclusions about the null and alternative hypotheses

]

---

class: center, middle, inverse

# Decisions in Hypothesis Testing

---

# Possible Truths in the World

.center[

**Truth**

.pull-left[
There is no effect, `\(H_{0}\)`
] 

.pull-right[
There is an effect, `\(H_{1}\)`
]
]

--

Because these are mutually exclusive and exhaustive, one of these has to be true and only one of them can be true

--

But _sampling error_ is always acting, so occasionally we’ll get samples that are different from the truth in the world, which will lead to erroneous conclusions

---

# Possible Decision Outcomes

.center[
&lt;img src="img/error-decision-1.png" width="85%"/&gt;
]

---

# Possible Decision Outcomes

.center[
&lt;img src="img/error-decision-2.png" width="85%"/&gt;
]

---

# Possible Decision Outcomes

.center[
&lt;img src="img/error-decision-3.png" width="85%"/&gt;
]

---

# Possible Decision Outcomes

.center[
&lt;img src="img/error-decision-4.png" width="85%"/&gt;
]

---

# Type I Error

.pull-left[

.content-box-gray[

**Type I error**: Occurs when there is _no_ effect present but the researcher rejects the null hypothesis

]
]

.pull-right[
&lt;img src="img/error-decision-4.png" /&gt;

]

--

Also known as a '_false alarm_', '_Alpha error_', or '**_False positive_**'

--

Simply put: Saying there is an effect, when there is actually no effect

---

# Decisions

.center[
&lt;img src="img/error-decision-5.png" width="85%"/&gt;
]

---

# Type II Error

.pull-left[
.content-box-gray[
**Type II error**: Occurs when a real effect _is_ present, but the researcher fails to reject the null hypothesis
]
]

.pull-right[
&lt;img src="img/error-decision-5.png" /&gt;

]

--

Also known as a '_miss_' or '_Beta error_', or '**_False negative_**'

--

Simply put: Saying there is no effect, when there is actually an effect

---

# Errors in Practical Terms

.center[
&lt;img src="https://upload.wikimedia.org/wikipedia/commons/d/d9/Smoke_detector.JPG" width="50%"/&gt;
]

---

# Errors in Practical Terms

.center[
&lt;img src="img/fire-1.png" width="85%"/&gt;

]

---

# Errors in Practical Terms

.center[
&lt;img src="img/fire-2.png" width="85%"/&gt;

]

---

# Errors in Practical Terms

.center[
&lt;img src="img/fire-3.png" width="85%"/&gt;

]

---

# Errors in Practical Terms

.center[
&lt;img src="img/fire-4.png" width="85%"/&gt;

]

---

# Errors in Practical Terms

.center[
&lt;img src="img/fire-5.png" width="85%"/&gt;

]

---

class: center, middle, inverse

# Class Activity

## Type I and Type II Errors

---

# Class Activity

.center[

With your classmates, come up with  an additional example of Type I and Type II errors. Draw them like the figure below.
]

.center[
&lt;img src="img/fire-5.png" width="70%"/&gt;

]


---

# Influences of Type I Errors

- A Type I error occurs when we reject `\(H_{0}\)` even though `\(H_{0}\)` is true

--

- In other words, we found something in the critical region and called it "extreme enough" to be a real effect, when in reality, it wasn't

--

- Recall that boundaries of the critical region are determined by alpha, which is under our control

---

# Critical Regions

The locations of the critical region boundaries for three different levels of significance: `\(\alpha = .05\)`, `\(\alpha = .01\)`, `\(\alpha = .001\)`

.center[

&lt;img src="img/critical-regions-at-different-alphas.png" width="65%"/&gt;
]

.footnote[

]

---

# Probability of a Type I Error

So, Type I error rates are under our control and their probability is simply equal to alpha (assuming that the true state of the world is that `\(H_{0}\)` is true)

--

If `\(H_{1}\)` is true, what proportion of the time could we have a false positive?

--

.center[
`\(p(Type \: I \: error \: | \: H_{1} \:is \: True) = 0\)`

]

--

.center[

`\(p(Type \: I \: error \: | \: H_{0} \:is \: True) = \alpha\)`

]

--

In other words: 

- If `\(H_{1}\)` is true, there is no risk of a Type I error

- If `\(H_{0}\)` is true, the risk of a Type I error is `\(\alpha\)`

---

# Probability of a Type I Error

.center[

&lt;img src="img/decision-table-1.png" width="80%"/&gt;
]

---

# Probability of a Type II Error

.center[

`\(p(Type \: II \: error \: | \: H_{1} \:is \: True) = \beta\)`

`\(p(Type \: II \: error \: | \: H_{0} \:is \: True) = 0\)`

]

--

In other words: 

- If `\(H_{1}\)` is true, the risk of a Type II error is `\(\beta\)`

- If `\(H_{0}\)` is true, there is no risk of a Type II error

.pull-right[
.content-box-blue[
.center[
**Beta**  
`$$\beta$$`
]
]
]

---

# Probability of a Type II Error

.center[

&lt;img src="img/decision-table-2.png" width="80%"/&gt;
]


---

# Probability of Specificity

.content-box-gray[
**Specificity**: The specificity of a test (also called the True Negative Rate) is the probability of failing to reject `\(H_{0}\)` when `\(H_{0}\)` is true
]

.center[

&lt;img src="img/decision-table-3.png" width="50%"/&gt;
]

---

# Statistical Power


.center[

&lt;img src="img/decision-table-4.png" width="80%"/&gt;
]


---

# Alpha and Beta

**Alpha**: probability of a false positive (Type I error)

**Beta**: probability of a false negative (Type II error)

--

- We know alpha ahead of time and it is under our control, but what about beta?

--

- We often don't know what it is equal to ahead of time, but beta comes from statistical power, `\(1-\beta\)`, which we will discuss next

---

class: center, middle, inverse

# Statistical Power

---

# Statistical Power

--

.pull-left[
.center[
&lt;img src="img/eyeglasses.png" width="50%"/&gt;
]
]

--

.pull-right[
.center[
&lt;img src="img/binoculars.png" width="50%"/&gt;
]
]

--

.pull-left[
.center[
&lt;img src="img/microscope.png" width="50%"/&gt;
]
]

--

.pull-right[
.center[
&lt;img src="img/telescope.png" width="50%"/&gt;
]
]



---

# Statistical Power

.content-box-gray[
**Statistical power**: the probability that the test will correctly reject a false null hypothesis. That is, power is the probability that the test will identify an effect if one really exists
]

--

Simply put: how well a test can _detect_ a real effect and reject the null hypothesis when the null hypothesis is, in fact, false
 
---

# Statistical Power

.pull-left[
.center[

**In the population**

`\(\mu\)` = 100  

`\(\sigma\)` = 15  



&lt;img src="img/brain.png" width="50%"/&gt;
]
]

.pull-right[

.center[


**Our sample**

`\(n = 100\)`  

`\(\overline{X}_{IQ} = 120\)`  

`\(s_{IQ} = 15\)`


&lt;img src="https://m.media-amazon.com/images/I/71wFJxZolUL._AC_SL1500_.jpg" width="20%"/&gt;

]
]

---

# Statistical Power

.center[
&lt;img src="img/stat-power-1.png" width="80%"/&gt;

]

---

# Statistical Power

.center[
&lt;img src="img/stat-power-2.png" width="80%"/&gt;

]

---

# Statistical Power

.center[
&lt;img src="img/stat-power-3.png" width="80%"/&gt;

]

---

# Statistical Power

.center[
&lt;img src="img/stat-power-4.png" width="75%"/&gt;

]

---

# Statistical Power

.center[
&lt;img src="img/stat-power-5.png" width="75%"/&gt;

]


---

# Influences of Statistical Power

- The **size of an effect** in the population

  - Bigger effect size <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"/></svg> more statistical power

---

# Effect Size

.content-box-blue[

.center[
**Cohen's _d_ for one-sample _z_-test**
]

.Large[
`$$d_{z} = \frac{\overline{x} - \mu}{\sigma}$$`

]
]

The size of an effect here would be how large our numerator is

`\(\overline{x}\)` estimates the mean under `\(H_{1}\)`

`\(\mu\)` is the mean under `\(H_{0}\)`

`\(\sigma\)` is the standard deviation under `\(H_{0}\)`

---

# Influences of Statistical Power

- The **size of an effect** in the population

  - Bigger effect size <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"/></svg> more statistical power

- **Variability** in the population
  - Less variability <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"/></svg> more statistical power

---

# Variability

.content-box-blue[
.center[
**_z_ Test Statistic**

.Large[
`$$z_{\overline{x}} = \frac{\overline{x} - \mu}{\sigma_{\overline{x}}}$$`
]
]
]

The more variability in the population, the larger the standard error, the smaller the test statistic

---

# Variability

.center[

&lt;img src="img/power-var-1.png" /&gt;

]

---

# Variability

.center[

&lt;img src="img/power-var-2.png" width="90%"/&gt;

]

---

# Influences of Statistical Power

- The **size of an effect** in the population

  - Bigger effect size <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"/></svg> more statistical power

- **Variability** in the population
  - Less variability <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"/></svg> more statistical power

- **Sample size**

  - Larger sample size <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"/></svg> more statistical power


---

# Sample Size

.pull-left[
As sample size increases, standard error decreases, the test statistic increases, and statistical power increases
]

.pull-right[

.content-box-blue[
.center[
**_z_ Test Statistic**
`$$z_{\overline{x}} = \frac{\overline{x} - \mu} {\sigma_{\overline{x}}}$$`
]
]


.content-box-blue[
.center[
**Standard Error**
`$$\sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}}$$`
]
]
]



---

# Influences of Statistical Power

- The **size of an effect** in the population

  - Bigger effect size <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"/></svg> more statistical power

- **Variability** in the population
  - Less variability <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"/></svg> more statistical power

- **Sample size**

  - Larger sample size <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"/></svg> more statistical power

- **Alpha level**: Bigger alpha level <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M190.5 66.9l22.2-22.2c9.4-9.4 24.6-9.4 33.9 0L441 239c9.4 9.4 9.4 24.6 0 33.9L246.6 467.3c-9.4 9.4-24.6 9.4-33.9 0l-22.2-22.2c-9.5-9.5-9.3-25 .4-34.3L311.4 296H24c-13.3 0-24-10.7-24-24v-32c0-13.3 10.7-24 24-24h287.4L190.9 101.2c-9.8-9.3-10-24.8-.4-34.3z"/></svg> more statistical power

---

# Alpha Level

.center[

&lt;img src="img/critical-regions-at-different-alphas.png" width="65%"/&gt;
]

---

class: center, middle, inverse

# Which error rates (Type I, Type II) should you aim for?

---

# Setting Alpha and Statistical Power

Usually we set `\(\alpha = 0.05\)` and statistical power, `\(1-\beta = 0.80\)` 

--

.pull-left[
.center[
**Alpha**  

This means in the _long run_,  
5% of our results will be Type I errors

.red[5% false positive rate]
]
]

--

.pull-right[
.center[
**Statistical power**  

This means in the _long run_,  
20% of our results will be Type II errors

.red[20% false negative rate]
]
]

---

# Setting Alpha and Statistical Power

.pull-left[
&gt; Is it more serious to convict an innocent man, or to acquit a guilty?
&gt; 
&gt; Determining how the balance must be struck should be left to the investigator.
&gt;
— &lt;cite&gt;Neyman &amp; Pearson, 1933&lt;/cite&gt;
]

.pull-right[

.center[
&lt;img src="https://alchetron.com/cdn/jerzy-neyman-d98b7785-25d2-4ff0-b956-ecc268b0b3a-resize-750.jpeg" /&gt;  
Jerzy Neyman

]
]

---

class: center, middle, inverse

# Class Activity

---

# Class Activity: Settting Error Rates

With your classmates, determine: 

.center[
What is an acceptable _false positive rate_ (Type I error), and why?


What is an acceptable _false negative rate_ (Type II error), and why?
]

--




**Example Research Questions**

- We are studying a new education program for increasing reading comprehension, and the intervention will cost $300,000 to implement

- We are studying a new forensic interviewing technique to better differentiate liars from truth-tellers

- We are studying whether violent video games cause aggression 

- We are studying whether social media use is associated with depression and anxiety symptoms


---

# Next time

.pull-left[

**Lecture**

- Midterm Review

**Reading**

- Chapter Nine

**Quiz**

- Quiz 2 is due tonight at 11:59pm MT

  - Lecture 4-6, Ch.6-8
  

]

.pull-right[

.center[

&lt;img src="https://static.vecteezy.com/system/resources/previews/004/334/351/non_2x/calendar-icon-schedule-icon-symbol-trendy-flat-style-free-vector.jpg" width="50%" /&gt;

]
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
